{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Brent Pedersen","text":"<p>I am a genomics researcher and software developer focused on creating useful, simple, fast and reliable tools for variant analysis and genomic data processing. I am looking for collaborative contract work that is interesting and impactful and where my skills can be best utilized.</p>"},{"location":"#work-with-me","title":"Work With Me","text":"<ul> <li>Are you struggling with quality control problems in your genomic studies?</li> <li>Is your variant processingn pipeline for clinical pipelines slow or incomplete?</li> <li>Do you need help with custom visualizations, a well-defined genomics tools or analyses?</li> </ul> <p>I am interested in bigger projects, but with less commitment (to you) than a staff member. My preferred model is 16 weeks (~\u2153rd year) of focused work of at least 1 day per week for a substantial financial and project commitment. I intend to have 2-3 projects at any given time.</p> <p>I am also open to projects that match my expertise and interest, if you have questions or a project, please contact me.</p> <p>Discuss A Project</p>"},{"location":"#recommendations","title":"Recommendations","text":"Loading recommendations..."},{"location":"#key-projects","title":"Key Projects","text":"<p>Here are some of my projects, each with an open-source repository that I still maintain and a publication describing it's use.</p> <ul> <li> <p> mosdepth  Fast BAM/CRAM depth calculation for WGS, exome, or targeted sequencing. Written in Nim for maximum performance.    Mosdepth: quick coverage calculation for genomes and exomes.</p> </li> <li> <p> somalier  Fast sample-swap and relatedness checks on BAMs/CRAMs/VCFs/GVCFs. Essential for quality control in genomic studies.    Somalier: rapid relatedness estimation for cancer and germline studies using efficient sketches.</p> </li> <li> <p> slivar  Genetic variant expressions, annotation, and filtering for great good. Streamlines variant analysis workflows.    Effective variant filtering and expected candidate variant yield in studies of rare human disease.</p> </li> <li> <p> vcfanno  Annotate a VCF with other VCFs/BEDs/tabixed files. Written in Go for speed and reliability.    VCFanno: fast, flexible annotation of genetic variants.</p> </li> <li> <p> cyvcf2  Cython + htslib for fast VCF and BCF processing. Core library for many Python-based genomic tools.    cyvcf2: fast, flexible variant analysis with Python/Cython.</p> </li> <li> <p> echtvar  Using all the bits for echt rapid variant annotation and filtering. Written in Rust for maximum performance.    Echtvar: compressed variant representation for rapid annotation and filtering of SNPs and indels.</p> </li> </ul>"},{"location":"#technical-expertise","title":"Technical Expertise","text":"<p>I have extensive experience in developing in rust, python/cython (extension modules and entire software), nim and go for high-performance bioinformatics tools. My expertise includes genomics, variant analysis, and performance optimization for large-scale genomic data processing.</p> <p>My work has been in developing efficient algorithms, largely in variant filtering, annotation, and QC. I like to add scripting capabilities to command-line tools to give maximum flexibility.</p>"},{"location":"#recent-activity","title":"Recent Activity","text":"<p>Check out the blog section for the latest posts and updates on my research and software development work.</p>"},{"location":"#connect","title":"Connect","text":"<ul> <li>GitHub: github.com/brentp</li> <li>Google Scholar: Profile</li> <li>Location: Oregon, USA</li> <li>Twitter: @brent_p</li> <li>email</li> </ul>"},{"location":"tags/","title":"Tags","text":"<p>Browse all available tags to find posts on specific topics.</p>"},{"location":"tags/#tag:ai","title":"ai","text":"<ul> <li>            AI Coding          </li> </ul>"},{"location":"tags/#tag:coding","title":"coding","text":"<ul> <li>            AI Coding          </li> </ul>"},{"location":"tags/#tag:javascript","title":"javascript","text":"<ul> <li>            AI Coding          </li> </ul>"},{"location":"tags/#tag:llms","title":"llms","text":"<ul> <li>            AI Coding          </li> </ul>"},{"location":"tags/#tag:rust","title":"rust","text":"<ul> <li>            AI Coding          </li> </ul>"},{"location":"tags/#tag:vcf","title":"vcf","text":"<ul> <li>            AI Coding          </li> </ul>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/2025/12/29/ai-coding/","title":"AI Coding","text":"<p>This post is mostly about AI coding. Jump to the end if you're more interested in genomics libraries.</p>","tags":["llms","ai","coding","vcf","rust","javascript"]},{"location":"blog/2025/12/29/ai-coding/#ai-coding","title":"AI Coding","text":"<p>I use AI coding tools quite a bit, but over the last couple of weeks without writing a line of code (I may have edited a README), I made</p> <ol> <li> <p>a rust package to easily apply javascript expressions to a genomic variant: https://brentp.github.io/htsvcf/latest/htsvcf/</p> </li> <li> <p>a javascript library for reading, writing VCF/BCF and modifying variants: https://www.npmjs.com/package/htsvcf</p> </li> </ol> <p>I mostly used opencode and either GPT-5.2 or Claude Opus 4.5 using my free github credits from having a \"popular\" open-source project (but I do have a $20/month Codex sub, a $20 Cursor sub, and a $3/month GLM sub). This was not possible prior to these models (and the progression of CLI coding tools). Opus 4.5 is very good; like it's different. And faster than GPT-5.2. Or previously, a project even smaller than this would at least require so much intervention that it would have taken much longer than it did and therefore have been infeasible as a side project/experiment. And, as a project grew, the complexity would bring down the efficacy of using LLMs; that didn't happen here. It's still a small project, but it's substantial and I do notice a sea-change.  I had never published an NPM package prior to this and now have one that's automatically published via github action to be available on linux x64 and arm along with OSX (can also support whatever NAPI supports). The models generally made code that I was happy with or that was easily adjusted with a single prompt.</p> <p>This was not a single \"vibe-code\", but rather on the order of 50 different individual prompts. I would decide a feature: \"Allow setting INFO fields in VCF\" or \"support extracting genotypes and return as <code>{ alleles: [0, 1], phase: [false]}</code> for <code>0/1</code>\" and then use <code>Plan</code> mode in opencode and then iterate on it and even ask it to find any holes in the plan. Once the plan was made, I'd let it go Brrrr in <code>Build</code> mode and sometimes check in, scroll-back through the output and occasionally intervene and interrupt it. My AGENTS.md indicates that the agent should update (specifically) <code>lib.rs</code> rust-docs and add tests and run <code>cargo clippy</code> and <code>fmt</code>. When it was done building, I'd look over the diff in cursor and sometimes ask an LLM there to note any problems with the diff. Sometimes I'd add a new requirement at this stage and go back into <code>opencode</code>. I left opencode to manage its own context.</p> <p>I tried Gemini 3.0 a couple times and on brief look the code it generated was fine, but it was having trouble making edits. It would inject in the wrong place and take time to figure out how to undo the change and then re-insert it into the correct file location. I didn't notice a single time where this happened with GPT 5.2 or Opus 4.5 though I didn't review all of the intermediate output.</p>","tags":["llms","ai","coding","vcf","rust","javascript"]},{"location":"blog/2025/12/29/ai-coding/#the-changing-ai-coding-experience","title":"The Changing AI Coding Experience","text":"<p>This library that I wrote/managed the writing of is based on something I wanted to do for a long time. I've been embedding scripting interfaces into genomics tools since 2016 and since then have found it quite useful. I prefer  Javascript syntax but it has always been easier to embed lua and still have good performance. I had an old <code>rust</code> repo where I had made a small example and tried to get help to understand why my minimal rust program with V8 scripting was leaking memory. I was not able to resolve that. In early december, I asked GPT 5.2 to fix the leak and make sure to update to latest v8 crate. It did, in one shot. And we went from  there. What was striking to me was the rate of change in improvement. I had the sense previously that things were plateauing--the models were getting better but it wasn't changing that much. This felt very different. I was continually 1, 2, or 3-shotting substantial features with  tests and documentation. I think writing a wrapper library is probably a nice use-case for the LLMs as they currently are, but the entire experience was easy. I guess there's a realization that this will continue to improve in months, not years and that what I offer now is taste and high-level guidance. I am excited about what I can build next. And also wondering what software engineering/programming will look like. And what will be my place in it. I don't have any deep thoughts here, just noticing this new reality encroaching.</p> <p>Below I'll write a bit about the actual libraries.</p>","tags":["llms","ai","coding","vcf","rust","javascript"]},{"location":"blog/2025/12/29/ai-coding/#htsvcf","title":"HTSVCF","text":"<p>Starting from the initial V8 Javascript::rust example project, I built, with opencode and LLMs, a library for rust-htslib that exposes most attributes  that are available on a variant in VCF format to Javascript expressions. Concurrently, it built a library to read and write VCF files from Javascript (via bun or node).</p>","tags":["llms","ai","coding","vcf","rust","javascript"]},{"location":"blog/2025/12/29/ai-coding/#rust","title":"rust","text":"<p>I am quite pleased with the syntax of the libraries. For the rust library that facilitates user expressions, the usage looks like this:</p> <pre><code>use htsvcf::Evaluator;\nuse rust_htslib::bcf::{self, Read};\n\nlet mut reader = bcf::Reader::from_path(\"input.vcf.gz\")?;\nlet mut eval = Evaluator::new(reader.header())?;\n\n// Optionally define custom functions\neval.run(\"function passes(v) { return v.info('DP') &gt; 20 }\")?;\n\nfor result in reader.records() {\n    let record = result?;\n    eval.set_record(record);\n\n    if eval.eval::&lt;bool&gt;(\"passes(variant)\")? {\n        // Use take() to get ownership of the record\n        let record = eval.take().unwrap();\n        // write record to output, collect it, etc.\n    }\n}\n</code></pre> <p>where the optional user function is:</p> <p><pre><code>function passes(v) { return v.info('DP') &gt; 20 }\n</code></pre> and the expression calling it is simply:</p> <pre><code>eval.eval::&lt;bool&gt;(\"passes(variant)\")\n</code></pre> <p>so we can handle other return times like i32, f32, f64, and (with some performance consequences) objects that serde::Deserialize can understand. <code>variant</code> is injected into the context for each variant (record) in the VCF file with <code>set_record</code>.</p> <p>There are other examples in the rust docs here</p>","tags":["llms","ai","coding","vcf","rust","javascript"]},{"location":"blog/2025/12/29/ai-coding/#javascript","title":"Javascript","text":"<p>The Javascript library is available from npm (<code>bun install -g htsvcf</code>). And usage looks like:</p> <pre><code>import { Reader, Writer } from \"htsvcf\";\n\nconst reader = new Reader(\"samples.vcf.gz\");\n\n// Print header info\nconsole.log(\"Samples:\", reader.header.samples());\nconst dpDef = reader.header.get(\"INFO\", \"DP\");\nconsole.log(`DP field: ${dpDef.type} (${dpDef.description})`);\n\n// Add a custom INFO field to the header\nreader.header.addInfo(\"HIGHQUAL\", \"0\", \"Flag\", \"Variant passed quality filter\");\n\n// Create a writer with the modified header\nconst writer = new Writer(\"filtered.vcf.gz\", reader.header);\n\n// Process variants. There's also a synchronous variant iterator that will be faster.\nfor await (const v of reader) {\n  // Translate variant to the writer's header (required after modifying header)\n  v.translate(writer.header);\n\n  // Filter by quality\n  if (v.qual !== null &amp;&amp; v.qual &lt; 30) continue;\n\n  // Set our custom flag\n  v.set_info(\"HIGHQUAL\", true);\n\n  // Get per-sample data\n  for (const s of v.samples()) {\n    if (s.DP !== null &amp;&amp; s.DP &gt; 10) {\n      console.log(`${v.chrom}:${v.pos} ${s.sample_name} DP=${s.DP}`);\n    }\n  }\n\n  // Write the variant\n  writer.write(v);\n}\n\nwriter.close();\nreader.close();\n</code></pre> <p>I have made efforts to keep both the rust and the Javascript side of things very fast. Please get in touch with any feedback.</p> <p>AI was not used to write this post.</p>","tags":["llms","ai","coding","vcf","rust","javascript"]},{"location":"blog/2025/12/29/ai-coding/#shameless-plug","title":"Shameless Plug","text":"<p>I have been doing contracting work in genomics for some time and am looking for substantial projects in 2026 that are suited to my skills and knowledge with the possibility of helping patients. Read more about that here and send me a message if you have something in mind.</p>","tags":["llms","ai","coding","vcf","rust","javascript"]},{"location":"drafts/","title":"Draft Posts","text":"<p>These posts are works in progress and are only visible when deploying from the dev branch.</p>"},{"location":"drafts/#current-drafts","title":"Current Drafts","text":"<p>No draft posts yet. Add markdown files to this directory to see them appear here.</p> <p>This page is only visible in dev deployments.</p>"},{"location":"blog/archive/2025/","title":"2025","text":""}]}